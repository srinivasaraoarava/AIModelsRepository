<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Models Repository - Top 6 Current Models</title>
    <link rel="stylesheet" href="styles.css">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
</head>
<body>
    <div class="container">
        <header class="header">
            <div class="logo">
                <h1>ü§ó AI Models Repository</h1>
                <p>Discover the top 6 trending AI models with comprehensive analysis</p>
            </div>
        </header>

        <main class="main-content">
            <div class="models-grid">
                <!-- Model 1: Qwen3-VL-30B -->
                <div class="model-card">
                    <div class="model-header">
                        <h2>Qwen/Qwen3-VL-30B-A3B-Instruct</h2>
                        <div class="model-stats">
                            <span class="downloads">412k downloads</span>
                            <span class="likes">208 likes</span>
                        </div>
                    </div>
                    <div class="model-type">Vision-Language Model</div>
                    
                    <div class="pros-cons-matrix">
                        <div class="pros">
                            <h3>‚úÖ Pros</h3>
                            <ul>
                                <li>Excellent vision-language understanding</li>
                                <li>High-quality image analysis</li>
                                <li>Multilingual support</li>
                                <li>Large context window</li>
                                <li>State-of-the-art performance</li>
                            </ul>
                        </div>
                        <div class="cons">
                            <h3>‚ùå Cons</h3>
                            <ul>
                                <li>Very large model size (30B parameters)</li>
                                <li>High computational requirements</li>
                                <li>Expensive inference costs</li>
                                <li>Long processing time</li>
                                <li>Requires specialized hardware</li>
                            </ul>
                        </div>
                    </div>
                </div>

                <!-- Model 2: GLM-4.6 -->
                <div class="model-card">
                    <div class="model-header">
                        <h2>zai-org/GLM-4.6</h2>
                        <div class="model-stats">
                            <span class="downloads">24.7k downloads</span>
                            <span class="likes">668 likes</span>
                        </div>
                    </div>
                    <div class="model-type">Large Language Model</div>
                    
                    <div class="pros-cons-matrix">
                        <div class="pros">
                            <h3>‚úÖ Pros</h3>
                            <ul>
                                <li>Excellent Chinese language support</li>
                                <li>Strong reasoning capabilities</li>
                                <li>Good code generation</li>
                                <li>Efficient architecture</li>
                                <li>Regular updates and improvements</li>
                            </ul>
                        </div>
                        <div class="cons">
                            <h3>‚ùå Cons</h3>
                            <ul>
                                <li>Limited availability in some regions</li>
                                <li>Primarily optimized for Chinese</li>
                                <li>Complex setup process</li>
                                <li>Memory intensive</li>
                                <li>Limited fine-tuning options</li>
                            </ul>
                        </div>
                    </div>
                </div>

                <!-- Model 3: NeuTTS-Air -->
                <div class="model-card">
                    <div class="model-header">
                        <h2>neuphonic/neutts-air</h2>
                        <div class="model-stats">
                            <span class="downloads">11.4k downloads</span>
                            <span class="likes">415 likes</span>
                        </div>
                    </div>
                    <div class="model-type">Text-to-Speech</div>
                    
                    <div class="pros-cons-matrix">
                        <div class="pros">
                            <h3>‚úÖ Pros</h3>
                            <ul>
                                <li>High-quality speech synthesis</li>
                                <li>Fast inference speed</li>
                                <li>Multiple voice options</li>
                                <li>Low latency processing</li>
                                <li>Easy API integration</li>
                            </ul>
                        </div>
                        <div class="cons">
                            <h3>‚ùå Cons</h3>
                            <ul>
                                <li>Limited language support</li>
                                <li>Requires specific audio format</li>
                                <li>Voice cloning limitations</li>
                                <li>Quality varies with input length</li>
                                <li>Commercial licensing required</li>
                            </ul>
                        </div>
                    </div>
                </div>

                <!-- Model 4: Apriel-1.5-15b-Thinker -->
                <div class="model-card">
                    <div class="model-header">
                        <h2>ServiceNow-AI/Apriel-1.5-15b-Thinker</h2>
                        <div class="model-stats">
                            <span class="downloads">9.24k downloads</span>
                            <span class="likes">351 likes</span>
                        </div>
                    </div>
                    <div class="model-type">Reasoning Model</div>
                    
                    <div class="pros-cons-matrix">
                        <div class="pros">
                            <h3>‚úÖ Pros</h3>
                            <ul>
                                <li>Advanced reasoning capabilities</li>
                                <li>Enterprise-grade performance</li>
                                <li>Strong analytical thinking</li>
                                <li>Optimized for business use cases</li>
                                <li>Reliable and stable outputs</li>
                            </ul>
                        </div>
                        <div class="cons">
                            <h3>‚ùå Cons</h3>
                            <ul>
                                <li>Limited creative generation</li>
                                <li>Slower processing for complex tasks</li>
                                <li>Requires domain expertise</li>
                                <li>Higher computational overhead</li>
                                <li>Enterprise licensing costs</li>
                            </ul>
                        </div>
                    </div>
                </div>

                <!-- Model 5: Ling-1T -->
                <div class="model-card">
                    <div class="model-header">
                        <h2>inclusionAI/Ling-1T</h2>
                        <div class="model-stats">
                            <span class="downloads">715 downloads</span>
                            <span class="likes">195 likes</span>
                        </div>
                    </div>
                    <div class="model-type">Multilingual Model</div>
                    
                    <div class="pros-cons-matrix">
                        <div class="pros">
                            <h3>‚úÖ Pros</h3>
                            <ul>
                                <li>Supports 1000+ languages</li>
                                <li>Inclusive AI approach</li>
                                <li>Low-resource language support</li>
                                <li>Cultural sensitivity</li>
                                <li>Open-source accessibility</li>
                            </ul>
                        </div>
                        <div class="cons">
                            <h3>‚ùå Cons</h3>
                            <ul>
                                <li>Variable quality across languages</li>
                                <li>Limited training data for rare languages</li>
                                <li>Performance trade-offs</li>
                                <li>Complex evaluation metrics</li>
                                <li>Maintenance challenges</li>
                            </ul>
                        </div>
                    </div>
                </div>

                <!-- Model 6: Llama 3.3 70B -->
                <div class="model-card">
                    <div class="model-header">
                        <h2>meta-llama/Llama-3.3-70B-Instruct</h2>
                        <div class="model-stats">
                            <span class="downloads">1.2M downloads</span>
                            <span class="likes">2.4k likes</span>
                        </div>
                    </div>
                    <div class="model-type">Large Language Model</div>
                    
                    <div class="pros-cons-matrix">
                        <div class="pros">
                            <h3>‚úÖ Pros</h3>
                            <ul>
                                <li>Exceptional performance across benchmarks</li>
                                <li>Strong instruction following</li>
                                <li>Excellent code generation</li>
                                <li>Open-source with permissive license</li>
                                <li>Large context window (128k tokens)</li>
                            </ul>
                        </div>
                        <div class="cons">
                            <h3>‚ùå Cons</h3>
                            <ul>
                                <li>Requires significant GPU memory (70B)</li>
                                <li>Slower inference than smaller models</li>
                                <li>High hosting costs</li>
                                <li>Quantization needed for consumer hardware</li>
                                <li>Large download size (~140GB)</li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
        </main>

        <footer class="footer">
            <p>Data sourced from <a href="https://huggingface.co/" target="_blank">Hugging Face</a> | Updated: January 2025</p>
        </footer>
    </div>
</body>
</html>
